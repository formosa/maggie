# Maggie AI Assistant Configuration - EXAMPLE
# Copy this file to config.yaml and modify as needed
# Optimized for AMD Ryzen 9 5900X and NVIDIA GeForce RTX 3080
# System configuration for performance and resource management

# System configuration
inactivity_timeout: 60  #  minutes in seconds

# Utility configuration
# STT configuration
stt:
  # Whisper STT configuration
  whisper:
    # Options: "base", "large"
    model_size: "base"
    # NEW: Use float16 for faster inference on RTX 3080
    compute_type: "float16" 
    # Path to Whisper model directory
    model_path: "\\maggie\\models\\stt\\whisper"
    # Sample rate for audio input 
    sample_rate: 16000 
  # NEW: Whisper streaming configuration
  whisper_streaming:
    # Enable streaming mode for real-time transcription
    enabled: true
    # Model name (same as whisper model_size if not specified)
    model_name: "base"
    # Language code
    language: "en"
    # Compute type (float16 for RTX 3080)
    compute_type: "float16"
    # Timeout for getting streaming results (seconds)
    result_timeout: 5.0
    # Buffer size in seconds
    buffer_size_seconds: 30.0
# Wake word detection configuration
  wake_word:
    # Options: "porcupine", "snowboy"
    engine: "porcupine"
    # Porcupine access key
    access_key: "9hQNkT59LV9YLj02ilmzaIg4zqUjX0YycaHTcHPEJuQ1/58G/r4BXA=="
    # Sensitivity for wake word detection
    sensitivity: 0.5
    # Porcupine wake word configuration
    keyword: "maggie"
    # Custom keyword file path (optional)
    keyword_path: "\\maggie\\models\\stt\\porcupine\\maggie_windows.ppn"
    # Maximum CPU usage percentage for wake word detection
    cpu_threshold: 5.0

# TTS configuration 
tts:
  voice_model: "af_heart.pt"
  model_path: "\\maggie\\models\\tts"
  sample_rate: 22050
  use_cache: true
  cache_dir: "\\maggie\\cache\\tts"
  cache_size: 200
  gpu_device: 0
  gpu_acceleration: true
  gpu_precision: "mixed_float16"
  max_workers: 4
  voice_preprocessing: true

# LLM configuration
llm:
  model_path: "maggie\\models\\llm\\mistral-7b-instruct-v0.3-GPTQ-4bit"
  model_type: "mistral"
  gpu_layers: 32  # Optimized for RTX 3080 10GB
  gpu_layer_auto_adjust: true  # NEW: Allow automatic adjustment based on available VRAM

# Logging configuration
logging:
  # Path to log directory
  path: "logs"
  # Log levels for console and file logging: DEBUG, INFO, WARNING, ERROR
  console_level: "INFO"
  # Separate level for file logging
  file_level: "DEBUG"

# Extensions configuration
extensions:
  # Enable or disable specific extension modules
  recipe_creator:
    # Enable or disable the recipe creator module
    enabled: true
    # Path to the recipe template file
    template_path: "templates\\recipe_template.docx"
    # Output directory for generated recipes
    output_dir: "recipes"

# CPU configuration
cpu:
  # Number of worker threads for parallel processing
  # (using 8 of the 12 available cores for Ryzen 9 5900X)
  max_threads: 8
  # Timeout for thread operations in seconds
  thread_timeout: 30  

# Memory configuration
memory:
  # Maximum memory usage for the application as a percentage of total system memory
  # (using up to 75% of system memory (24GB) from 32GB system)
  max_percent: 75
  # Threshold for unloading models to free up memory
  # (unload models if memory usage exceeds 85%)
  model_unload_threshold: 85

# GPU configuration
gpu:
  # Maximum GPU memory usage as a percentage of total GPU memory
  # (using up to 90% of RTX3080 (10 GB VRAM) memory)
  max_percent: 90
  # Threshold for unloading models to free up memory
  # (unload models if memory usage exceeds 95%)
  model_unload_threshold: 95